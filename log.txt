1
./data
./data
2
Create and initialize networks.
end
Encoder(
  (main): Sequential(
    (initial-conv-1-64): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), bias=False)
    (initial-64-batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (initial-relu-64): LeakyReLU(negative_slope=0.2, inplace=True)
    (pyramid-64-128-conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), bias=False)
    (pyramid-128-batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (pyramid-128-relu): LeakyReLU(negative_slope=0.2, inplace=True)
    (final-128-256-conv): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), bias=False)
    (final-256-tanh): Tanh()
  )
)
Decoder(
  (main): Sequential(
    (initial-256-256-convt): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (initial-256-batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (initial-256-relu): ReLU(inplace=True)
    (pyramid-256-128-convt): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (pyramid-128-batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (pyramid-128-relu): ReLU(inplace=True)
    (pyramid-128-64-convt): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (pyramid-64-batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (pyramid-64-relu): ReLU(inplace=True)
    (final-64-1-convt): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (final-1-tanh): Tanh()
  )
)
Dl(
  (main): Sequential(
    (fc-256-128): Linear(in_features=256, out_features=128, bias=True)
    (relu-128): LeakyReLU(negative_slope=0.2, inplace=True)
    (fc-128-64): Linear(in_features=128, out_features=64, bias=True)
    (relu-64): LeakyReLU(negative_slope=0.2, inplace=True)
    (fc-64-32): Linear(in_features=64, out_features=32, bias=True)
    (relu-32): LeakyReLU(negative_slope=0.2, inplace=True)
    (fc-32-16): Linear(in_features=32, out_features=16, bias=True)
    (relu-16): LeakyReLU(negative_slope=0.2, inplace=True)
    (fc-16-1): Linear(in_features=16, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
Dv(
  (classifier): Sequential(
    (0): Conv2d(1, 12, kernel_size=(5, 5), stride=(2, 2), bias=False)
    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): Conv2d(12, 24, kernel_size=(5, 5), stride=(2, 2), bias=False)
    (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): Conv2d(24, 48, kernel_size=(5, 5), stride=(2, 2), bias=False)
    (7): Tanh()
  )
  (linear): Sequential(
    (linear): Linear(in_features=48, out_features=1, bias=True)
    (Sigmoid): Sigmoid()
  )
)
Classfier(
  (classifier): Sequential(
    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), bias=False)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), bias=False)
    (7): Tanh()
  )
  (linear): Sequential(
    (linear): Linear(in_features=256, out_features=1, bias=True)
    (Sigmoid): Sigmoid()
  )
)
Initialize input tensors.
end
Setup optimizer
end
3
>> Training model ocgan.
